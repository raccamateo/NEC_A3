{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline  \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# fetch dataset \n",
    "hcv_data = fetch_ucirepo(id=571)\n",
    "\n",
    "# data (as pandas dataframes) \n",
    "X = hcv_data.data.features \n",
    "y = hcv_data.data.targets\n",
    "\n",
    "# metadata \n",
    "print(hcv_data.metadata)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b08c26130166b680"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# variable information \n",
    "print(hcv_data.variables)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f7a9a3c5f38f78c0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Identify categorical and numerical columns\n",
    "categorical_cols = ['Sex']  # Replace with your actual categorical columns\n",
    "numerical_cols = X.columns.difference(categorical_cols + ['ID'])  # Exclude 'ID' and categorical columns"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "898044f57c3edb98"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    " # Define the preprocessing pipelines for both numerical and categorical data\n",
    "numerical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),  # Replace missing values with the mean\n",
    "    ('scaler', StandardScaler())  # Standardize numerical features\n",
    "])\n",
    "\n",
    "categorical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),  # Replace missing values with the most frequent\n",
    "    ('encoder', OneHotEncoder(drop='if_binary'))  # Encode binary categorical features\n",
    "])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "66de0199f500069c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Combine preprocessing pipelines\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', numerical_pipeline, numerical_cols),\n",
    "    ('cat', categorical_pipeline, categorical_cols)\n",
    "])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c6955d64d7753845"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Preprocess the features\n",
    "X_preprocessed = preprocessor.fit_transform(X)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6b1fa5655e80df9f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Convert preprocessed data back to a DataFrame for easy manipulation and saving\n",
    "X_preprocessed_df = pd.DataFrame(X_preprocessed, index=X.index,\n",
    "                                 columns=(numerical_cols.tolist() + preprocessor.named_transformers_['cat'].named_steps['encoder'].get_feature_names_out(categorical_cols).tolist()))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8e797b3265690173"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Save the preprocessed data to a new CSV file\n",
    "X_preprocessed_df.to_csv('preprocessed_hcv_data.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ce830fb967228ac5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Apply PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_preprocessed_df)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "72b48c5c430018f0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Convert y to a numpy array\n",
    "y_array = np.array(y).flatten() if isinstance(y, pd.DataFrame) else y"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "364e566c20e570f2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create scatter plot of the first two principal components\n",
    "plt.figure(figsize=(12, 6))\n",
    "colors = ['navy', 'turquoise', 'darkorange', 'red', 'purple']\n",
    "\n",
    "# Ensure unique labels are sorted or in expected order\n",
    "unique_labels = sorted(np.unique(y_array))\n",
    "color_map = dict(zip(unique_labels, colors))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d43842ae684553c2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Scatter plot\n",
    "for label in unique_labels:\n",
    "    index = y_array == label\n",
    "    plt.scatter(X_pca[index, 0], X_pca[index, 1], color=color_map[label], alpha=.8, label=label)\n",
    "\n",
    "plt.legend(loc='best', shadow=False, scatterpoints=1)\n",
    "plt.title('PCA of HCV dataset')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "15a1ba40841f1e33"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Scree plot\n",
    "plt.figure(figsize=(6, 4))\n",
    "pca_variance = pca.explained_variance_ratio_\n",
    "plt.plot(np.cumsum(pca_variance))\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.title('Scree Plot')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "588d32038ba870e4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(pca_variance)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a26e95a4bca59f6a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#As the variance reaches only about 35 percent let's try with 4 components\n",
    "# Apply PCA with 4 components\n",
    "pca_4 = PCA(n_components=4)\n",
    "X_pca_4 = pca_4.fit_transform(X_preprocessed_df)\n",
    "\n",
    "# Calculate the explained variance\n",
    "pca_variance_4 = pca_4.explained_variance_ratio_\n",
    "\n",
    "# Print the explained variance for each component\n",
    "print(\"Explained variance for each component:\", pca_variance_4)\n",
    "\n",
    "# Create an updated scree plot with 4 components\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(range(1, len(pca_variance_4) + 1), np.cumsum(pca_variance_4), marker='o')\n",
    "plt.title('Scree Plot with 4 Components')\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.xticks(range(1, len(pca_variance_4) + 1))\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "718dc3d9a0d1765c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#With 4 components the variance reaches around 60 and in this case it could be more useful for further works with PCA"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f64625af04c84a8c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#t-SNE\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Flatten 'y' to a 1D array if it's a column vector\n",
    "y_flat = y.values.ravel() if isinstance(y, pd.DataFrame) else y\n",
    "\n",
    "# Now use 'y_flat' for label encoding and plotting\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y_flat)\n",
    "\n",
    "\n",
    "# Initialize t-SNE with a reasonable perplexity value\n",
    "tsne = TSNE(n_components=2, perplexity=36, random_state=42)\n",
    "\n",
    "# Apply t-SNE to the preprocessed data\n",
    "X_tsne = tsne.fit_transform(X_preprocessed_df)\n",
    "\n",
    "# Create a scatter plot for t-SNE projections\n",
    "plt.figure(figsize=(10, 10))\n",
    "unique_labels = np.unique(y_encoded)\n",
    "colors = ['navy', 'turquoise', 'darkorange', 'red', 'purple', 'green'] \n",
    "\n",
    "for i, label in enumerate(unique_labels):\n",
    "    plt.scatter(X_tsne[y_encoded == label, 0], X_tsne[y_encoded == label, 1], \n",
    "                color=colors[i], label=label_encoder.inverse_transform([label])[0])\n",
    "\n",
    "plt.legend()\n",
    "plt.title('t-SNE projection of HCV dataset')\n",
    "plt.xlabel('t-SNE feature 1')\n",
    "plt.ylabel('t-SNE feature 2')\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9749e46dabe57a13"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# k-means\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "max_k = 5  \n",
    "\n",
    "# Iterate over the range of k values\n",
    "for k in range(2, max_k + 1):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(X_preprocessed_df)  \n",
    "    cluster_labels = kmeans.labels_\n",
    "    \n",
    "    # Project the cluster labels back onto the PCA-reduced data for visualization\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.scatter(X_pca[:, 0], X_pca[:, 1], c=cluster_labels, cmap='viridis', alpha=0.6)\n",
    "    plt.colorbar(ticks=range(k))\n",
    "    plt.title(f'k-Means Clustering with k={k}')\n",
    "    plt.xlabel('PCA Component 1')\n",
    "    plt.ylabel('PCA Component 2')\n",
    "    plt.show()\n",
    "    \n",
    "    # If k equals the true number of classes, create a confusion matrix\n",
    "    if k == len(np.unique(y_encoded)):  # Update this condition if you know the true number of classes\n",
    "        cm = confusion_matrix(y_encoded, cluster_labels)\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "        plt.title(f'Confusion Matrix for k={k}')\n",
    "        plt.xlabel('Predicted Class')\n",
    "        plt.ylabel('True Class')\n",
    "        plt.show()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "704af7675db75488"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# k-menas analysis/interpretation:\n",
    "\n",
    "#The diagonal cells on the confusion matrix represent the number of points for which the predicted cluster matches the actual class (true positives).\n",
    "#Off-diagonal cells show where points from one class were placed into a different cluster (false positives/negatives).\n",
    "#From the matrix, it seems that one class (likely the majority class) is dominating two clusters (0 and 1), suggesting that k-means is having difficulty distinguishing between some of the classes. The other classes appear to be more evenly distributed across clusters, but with no clear one-to-one correspondence, indicating some degree of misclassification."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dca232f29128da3f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Let's advance with AHC"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "32cae5d2ef749fbd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Compute the pairwise distances of the preprocessed data\n",
    "dist_matrix = pairwise_distances(X_preprocessed_df)\n",
    "\n",
    "# Perform AHC with UPGMA linkage\n",
    "upgma_linkage = linkage(dist_matrix, method='average')\n",
    "\n",
    "# Perform AHC with complete linkage\n",
    "complete_linkage = linkage(dist_matrix, method='complete')\n",
    "\n",
    "# Truncated dendrogram for UPGMA linkage\n",
    "plt.figure(figsize=(12, 6))\n",
    "dendrogram(\n",
    "    upgma_linkage,\n",
    "    truncate_mode='lastp',  # show only the last p merged clusters\n",
    "    p=10,  # show only the last 10 merged clusters\n",
    "    show_leaf_counts=False,  # otherwise numbers in brackets are counts\n",
    "    leaf_rotation=90.,\n",
    "    leaf_font_size=12.,\n",
    "    show_contracted=True,  # to get a distribution impression in truncated branches\n",
    ")\n",
    "plt.title('Truncated Dendrogram for AHC using UPGMA Linkage')\n",
    "plt.xlabel('Cluster size')\n",
    "plt.ylabel('Distance')\n",
    "plt.show()\n",
    "\n",
    "# Truncated dendrogram for Complete linkage\n",
    "plt.figure(figsize=(12, 6))\n",
    "dendrogram(\n",
    "    complete_linkage,\n",
    "    truncate_mode='lastp',  # same as above\n",
    "    p=10,\n",
    "    show_leaf_counts=False,\n",
    "    leaf_rotation=90.,\n",
    "    leaf_font_size=12.,\n",
    "    show_contracted=True,\n",
    ")\n",
    "plt.title('Truncated Dendrogram for AHC using Complete Linkage')\n",
    "plt.xlabel('Cluster size')\n",
    "plt.ylabel('Distance')\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5bab7cba484b93a5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Let's advance with the last part on this dataset: SOM"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2dfc81302390783"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from minisom import MiniSom\n",
    "\n",
    "# Initialize and train the SOM\n",
    "som = MiniSom(x=10, y=10, input_len=X_preprocessed_df.shape[1], sigma=0.7, learning_rate=0.35)\n",
    "som.train_random(X_preprocessed_df.values, num_iteration=5000)\n",
    "\n",
    "# Visualize the SOM with a U-matrix\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.pcolor(som.distance_map().T, cmap='bone_r')  # distance map as background\n",
    "plt.colorbar()\n",
    "\n",
    "# Overlay with class labels\n",
    "markers = ['o', 's', 'D', '+', 'x']  # as many markers as there are classes\n",
    "colors = ['r', 'g', 'b', 'c', 'm']   # colors for the markers\n",
    "for cnt, xx in enumerate(X_preprocessed_df.values):\n",
    "    w = som.winner(xx)  # getting the winner\n",
    "    # place a marker on the winning position for the sample xx\n",
    "    plt.plot(w[0]+.5, w[1]+.5, markers[y_encoded[cnt]], markerfacecolor='None',\n",
    "             markeredgecolor=colors[y_encoded[cnt]], markersize=12, markeredgewidth=2)\n",
    "\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fc05a04796bd913c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot the component planes\n",
    "num_features = X_preprocessed_df.shape[1]\n",
    "fig, axs = plt.subplots(num_features, figsize=(num_features*5, 250))\n",
    "for i, ax in enumerate(axs):\n",
    "    ax.pcolor(som.get_weights()[:, :, i], cmap='coolwarm')\n",
    "    ax.set_title(f'Component plane for feature {i}')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a37f88f0a775d649"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
